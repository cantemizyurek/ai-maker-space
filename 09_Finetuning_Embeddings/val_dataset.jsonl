{"questions": {"f08a2cdf-844a-4cee-b3df-293fb573b43b": "What are some of the different tools that various systems can use to solve problems, as mentioned in the context?", "0912fc30-1838-4f87-9591-4b515c695313": "Why is it important to understand CSP and CORS HTTP headers when building a Claude Artifact that interacts with an external API?", "548d6b00-878a-453f-9c36-4a9402d2cfab": "According to the context, why are LLMs described as \"chainsaws disguised as kitchen knives\"?", "b4dea504-cb2d-4a05-98c8-4425eefbcf48": "What factors influence whether a computer system built to answer questions in human language will provide accurate answers?", "3fe0f570-c0b7-4b9b-873c-91406bd098b7": "What are some of the limitations that o1 still faces despite improvements in its capabilities?", "5558b582-9be7-4ed5-aa4d-af346bf6f618": "How does the default LLM chat UI compare to introducing new users to a Linux terminal, according to the context?", "986c0ca6-2d9b-4964-9c3b-a658e61aa904": "How does the complexity of token relationships in organic datasets affect a model's ability to learn from next-token prediction?", "ce06ff02-17be-4040-8244-d77d15cac175": "Why is it easier for a language model to follow reasoning patterns when generating tokens compared to learning from organic datasets?", "fe3d0044-6d4a-4c26-be30-3a9efee1400a": "What significant change occurred in 2024 regarding the use of the word \"slop\"?", "ef51728b-96ca-47bf-80ce-552896d57d59": "Who originally tweeted about \"slop,\" prompting further discussion and writing on the topic?", "dd469055-a82c-4b16-972f-d846c745525c": "What role does synthetic data play in the pretraining of the Phi series of models?", "4ac38d43-ec7f-4113-b4d0-fd105d123dc6": "How does synthetic data offer advantages over organic data according to the provided context?", "80da137d-04f4-494f-8f9f-aa6f6dec8fbe": "Why is it considered unreliable to use a screenshot from ChatGPT to win an argument?", "5b92a1a4-b637-465e-93f1-02b5e7421ec9": "What issue arises from end users developing inaccurate mental models of how AI models like ChatGPT work?", "98b5446d-49a9-4e64-94a9-52d51bf843ac": "What does the term \u201cslop\u201d refer to in the context of generative AI, and why is it considered a negative practice?", "2d1747c6-1f46-4b3e-8be0-a2d2a68729ea": "How does the concept of \u201cmodel collapse\u201d relate to training AI models on synthetic or recursively generated data?", "03568ba0-7940-49bf-a91f-3a45c39f5f51": "According to the context, what is the key skill required to get the most out of LLMs?", "dd16d2e3-7ba2-4965-8133-7bdb718c8ac0": "What issue does the context highlight regarding the distribution of knowledge about tools like ChatGPT and Claude?", "a0139fb4-cd8b-4e19-b59a-0ef50c7cb228": "How are larger models being used to assist in the creation of training data for smaller language models according to the context?", "e5ac46be-43e4-4d19-b1c7-7bf5bf76e585": "What shift in training data practices for LLMs is described, compared to earlier methods of data collection?", "b1edacb9-7c64-4406-ae79-b8d66c5e490e": "How is the term \"slop\" being defined in the context of AI-generated content, and how does it compare to the term \"spam\" in relation to unwanted emails?", "20026e6d-9b07-4ed0-9526-9f9ba3937829": "Why does the author believe that concise terminology like \"slop\" is important for society when discussing modern AI?", "d0c54408-7e88-4d09-9718-442eebc74427": "According to the context, what is the common fear regarding AI models training on AI-generated content?", "1d6012c2-3a4a-4d34-b17a-177496b2b450": "How are AI labs actually using synthetic content in the training of their models, as described in the context?"}, "relevant_contexts": {"f08a2cdf-844a-4cee-b3df-293fb573b43b": ["251f61a0-8130-46f5-9c8e-d1af3602daea"], "0912fc30-1838-4f87-9591-4b515c695313": ["251f61a0-8130-46f5-9c8e-d1af3602daea"], "548d6b00-878a-453f-9c36-4a9402d2cfab": ["ce09d641-98f1-4f4d-8fa6-f1aba55acfb9"], "b4dea504-cb2d-4a05-98c8-4425eefbcf48": ["ce09d641-98f1-4f4d-8fa6-f1aba55acfb9"], "3fe0f570-c0b7-4b9b-873c-91406bd098b7": ["bb6933ed-9135-458b-9158-91e749a7b341"], "5558b582-9be7-4ed5-aa4d-af346bf6f618": ["bb6933ed-9135-458b-9158-91e749a7b341"], "986c0ca6-2d9b-4964-9c3b-a658e61aa904": ["598ef854-78c8-47c1-8b0c-76d524d637b9"], "ce06ff02-17be-4040-8244-d77d15cac175": ["598ef854-78c8-47c1-8b0c-76d524d637b9"], "fe3d0044-6d4a-4c26-be30-3a9efee1400a": ["84076bf0-2525-4670-90ed-f9ddab56d138"], "ef51728b-96ca-47bf-80ce-552896d57d59": ["84076bf0-2525-4670-90ed-f9ddab56d138"], "dd469055-a82c-4b16-972f-d846c745525c": ["575ae791-bb38-47d4-a489-145d9fa82e98"], "4ac38d43-ec7f-4113-b4d0-fd105d123dc6": ["575ae791-bb38-47d4-a489-145d9fa82e98"], "80da137d-04f4-494f-8f9f-aa6f6dec8fbe": ["47308bab-13fe-4985-af41-20301a17fd9e"], "5b92a1a4-b637-465e-93f1-02b5e7421ec9": ["47308bab-13fe-4985-af41-20301a17fd9e"], "98b5446d-49a9-4e64-94a9-52d51bf843ac": ["7d070c8c-d54f-4f29-b728-181235fffea1"], "2d1747c6-1f46-4b3e-8be0-a2d2a68729ea": ["7d070c8c-d54f-4f29-b728-181235fffea1"], "03568ba0-7940-49bf-a91f-3a45c39f5f51": ["66cb2667-b974-4167-a008-743ad787e6d4"], "dd16d2e3-7ba2-4965-8133-7bdb718c8ac0": ["66cb2667-b974-4167-a008-743ad787e6d4"], "a0139fb4-cd8b-4e19-b59a-0ef50c7cb228": ["3dc50db5-b895-423a-8e45-135e6320ef70"], "e5ac46be-43e4-4d19-b1c7-7bf5bf76e585": ["3dc50db5-b895-423a-8e45-135e6320ef70"], "b1edacb9-7c64-4406-ae79-b8d66c5e490e": ["56cbec6f-6a0e-4d64-8262-1f0517907959"], "20026e6d-9b07-4ed0-9526-9f9ba3937829": ["56cbec6f-6a0e-4d64-8262-1f0517907959"], "d0c54408-7e88-4d09-9718-442eebc74427": ["cced63b3-b5d8-45f0-a538-1fd4997dfbe0"], "1d6012c2-3a4a-4d34-b17a-177496b2b450": ["cced63b3-b5d8-45f0-a538-1fd4997dfbe0"]}, "corpus": {"84076bf0-2525-4670-90ed-f9ddab56d138": "The year of slop\n2024 was the year that the word \"slop\" became a term of art. I wrote about this in May, expanding on this tweet by @deepfates:", "56cbec6f-6a0e-4d64-8262-1f0517907959": "Watching in real time as \u201cslop\u201d becomes a term of art. the way that \u201cspam\u201d became the term for unwanted emails, \u201cslop\u201d is going in the dictionary as the term for unwanted AI generated content\n\nI expanded that definition a tiny bit to this:\n\nSlop describes AI-generated content that is both unrequested and unreviewed.\n\nI ended up getting quoted talking about slop in both the Guardian and the NY Times. Here\u2019s what I said in the NY TImes:\n\nSociety needs concise ways to talk about modern A.I. \u2014 both the positives and the negatives. \u2018Ignore that email, it\u2019s spam,\u2019 and \u2018Ignore that article, it\u2019s slop,\u2019 are both useful lessons.", "7d070c8c-d54f-4f29-b728-181235fffea1": "I love the term \u201cslop\u201d because it so succinctly captures one of the ways we should not be using generative AI!\nSlop was even in the running for Oxford Word of the Year 2024, but it lost to brain rot.\nSynthetic training data works great\nAn idea that surprisingly seems to have stuck in the public consciousness is that of \u201cmodel collapse\u201d. This was first described in the paper The Curse of Recursion: Training on Generated Data Makes Models Forget in May 2023, and repeated in Nature in July 2024 with the more eye-catching headline AI models collapse when trained on recursively generated data.", "cced63b3-b5d8-45f0-a538-1fd4997dfbe0": "The idea is seductive: as the internet floods with AI-generated slop the models themselves will degenerate, feeding on their own output in a way that leads to their inevitable demise!\nThat\u2019s clearly not happening. Instead, we are seeing AI labs increasingly train on synthetic content\u2014deliberately creating artificial data to help steer their models in the right way.\nOne of the best descriptions I\u2019ve seen of this comes from the Phi-4 technical report, which included this:", "575ae791-bb38-47d4-a489-145d9fa82e98": "Synthetic data as a substantial component of pretraining is becoming increasingly common, and the Phi series of models has consistently emphasized the importance of synthetic data. Rather than serving as a cheap substitute for organic data, synthetic data has several direct advantages over organic data.", "598ef854-78c8-47c1-8b0c-76d524d637b9": "Structured and Gradual Learning. In organic datasets, the relationship between tokens is often complex and indirect. Many reasoning steps may be required to connect the current token to the next, making it challenging for the model to learn effectively from next-token prediction. By contrast, each token generated by a language model is by definition predicted by the preceding tokens, making it easier for a model to follow the resulting reasoning patterns.", "3dc50db5-b895-423a-8e45-135e6320ef70": "Another common technique is to use larger models to help create training data for their smaller, cheaper alternatives\u2014a trick used by an increasing number of labs. DeepSeek v3 used \u201creasoning\u201d data created by DeepSeek-R1. Meta\u2019s Llama 3.3 70B fine-tuning used over 25M synthetically generated examples.\nCareful design of the training data that goes into an LLM appears to be the entire game for creating these models. The days of just grabbing a full scrape of the web and indiscriminately dumping it into a training run are long gone.\nLLMs somehow got even harder to use", "ce09d641-98f1-4f4d-8fa6-f1aba55acfb9": "A drum I\u2019ve been banging for a while is that LLMs are power-user tools\u2014they\u2019re chainsaws disguised as kitchen knives. They look deceptively simple to use\u2014how hard can it be to type messages to a chatbot?\u2014but in reality you need a huge depth of both understanding and experience to make the most of them and avoid their many pitfalls.\nIf anything, this problem got worse in 2024.\nWe\u2019ve built computer systems you can talk to in human language, that will answer your questions and usually get them right! ... depending on the question, and how you ask it, and whether it\u2019s accurately reflected in the undocumented and secret training set.", "251f61a0-8130-46f5-9c8e-d1af3602daea": "The number of available systems has exploded. Different systems have different tools they can apply to your problems\u2014like Python and JavaScript and web search and image generation and maybe even database lookups... so you\u2019d better understand what those tools are, what they can do and how to tell if the LLM used them or not.\nDid you know ChatGPT has two entirely different ways of running Python now?\nWant to build a Claude Artifact that talks to an external API? You\u2019d better understand CSP and CORS HTTP headers first.", "bb6933ed-9135-458b-9158-91e749a7b341": "The models may have got more capable, but most of the limitations remained the same. OpenAI\u2019s o1 may finally be able to (mostly) count the Rs in strawberry, but its abilities are still limited by its nature as an LLM and the constraints placed on it by the harness it\u2019s running in. o1 can\u2019t run web searches or use Code Interpreter, but GPT-4o can\u2014both in that same ChatGPT UI. (o1 will pretend to do those things if you ask it to, a regression to the URL hallucinations bug from early 2023).\nWhat are we doing about this? Not much. Most users are thrown in at the deep end. The default LLM chat UI is like taking brand new computer users, dropping them into a Linux terminal and expecting them to figure it all out.", "47308bab-13fe-4985-af41-20301a17fd9e": "Meanwhile, it\u2019s increasingly common for end users to develop wildly inaccurate mental models of how these things work and what they are capable of. I\u2019ve seen so many examples of people trying to win an argument with a screenshot from ChatGPT\u2014an inherently ludicrous proposition, given the inherent unreliability of these models crossed with the fact that you can get them to say anything if you prompt them right.", "66cb2667-b974-4167-a008-743ad787e6d4": "There\u2019s a flipside to this too: a lot of better informed people have sworn off LLMs entirely because they can\u2019t see how anyone could benefit from a tool with so many flaws. The key skill in getting the most out of LLMs is learning to work with tech that is both inherently unreliable and incredibly powerful at the same time. This is a decidedly non-obvious skill to acquire!\nThere is so much space for helpful education content here, but we need to do do a lot better than outsourcing it all to AI grifters with bombastic Twitter threads.\nKnowledge is incredibly unevenly distributed\nMost people have heard of ChatGPT by now. How many have heard of Claude?"}}