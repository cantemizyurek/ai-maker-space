{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-IqJAMkwnCF"
      },
      "source": [
        "# Advanced Retrieval with LangChain\n",
        "\n",
        "In the following notebook, we'll explore various methods of advanced retrieval using LangChain!\n",
        "\n",
        "We'll touch on:\n",
        "\n",
        "- Naive Retrieval\n",
        "- Best-Matching 25 (BM25)\n",
        "- Multi-Query Retrieval\n",
        "- Parent-Document Retrieval\n",
        "- Contextual Compression (a.k.a. Rerank)\n",
        "- Ensemble Retrieval\n",
        "- Semantic chunking\n",
        "\n",
        "We'll also discuss how these methods impact performance on our set of documents with a simple RAG chain.\n",
        "\n",
        "There will be two breakout rooms:\n",
        "\n",
        "- ğŸ¤ Breakout Room Part #1\n",
        "  - Task 1: Getting Dependencies!\n",
        "  - Task 2: Data Collection and Preparation\n",
        "  - Task 3: Setting Up QDrant!\n",
        "  - Task 4-10: Retrieval Strategies\n",
        "- ğŸ¤ Breakout Room Part #2\n",
        "  - Activity: Evaluate with Ragas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rKP3hgHivpe"
      },
      "source": [
        "# ğŸ¤ Breakout Room Part #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xes8oT-xHN7"
      },
      "source": [
        "## Task 1: Getting Dependencies!\n",
        "\n",
        "We're going to need a few specific LangChain community packages, like OpenAI (for our [LLM](https://platform.openai.com/docs/models) and [Embedding Model](https://platform.openai.com/docs/guides/embeddings)) and Cohere (for our [Reranker](https://cohere.com/rerank)).\n",
        "\n",
        "> You do not need to run the following cells if you are running this notebook locally. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkgFAXWVW3wm",
        "outputId": "636db35c-f05a-4038-ec7a-02360bef2dae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/49.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/44.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/233.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m233.1/233.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m378.1/378.1 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m139.1/139.1 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "#!pip install -qU langchain langchain-openai langchain-cohere rank_bm25"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKqYM4Eoxcov"
      },
      "source": [
        "We're also going to be leveraging [Qdrant's](https://qdrant.tech/documentation/frameworks/langchain/) (pronounced \"Quadrant\") VectorDB in \"memory\" mode (so we can leverage it locally in our colab environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6xav5CxYnML"
      },
      "outputs": [],
      "source": [
        "#!pip install -qU qdrant-client"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7OHJXzfyJyA"
      },
      "source": [
        "We'll also provide our OpenAI key, as well as our Cohere API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LttlDQUYgSI",
        "outputId": "9dca95ab-4d02-4adf-ec3f-cb831326dc54"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API Key:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iUahNiJyQbv",
        "outputId": "78bf06ef-2ee8-46c3-f73d-27958b4dd79b"
      },
      "outputs": [],
      "source": [
        "os.environ[\"COHERE_API_KEY\"] = getpass.getpass(\"Cohere API Key:\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0pDRFEWSXvh"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw304iAFyRtl"
      },
      "source": [
        "## Task 2: Data Collection and Preparation\n",
        "\n",
        "We'll be using some reviews from the 4 movies in the John Wick franchise today to explore the different retrieval strategies.\n",
        "\n",
        "These were obtained from IMDB, and are available in the [AIM Data Repository](https://github.com/AI-Maker-Space/DataRepository)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXKHcZmKzDwT"
      },
      "source": [
        "### Data Collection\n",
        "\n",
        "We can simply `wget` these from GitHub.\n",
        "\n",
        "You could use any review data you wanted in this step - just be careful to make sure your metadata is aligned with your choice."
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 8,
=======
      "execution_count": 3,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbbSIGtzX3dS",
        "outputId": "0ce6514e-2479-4001-af24-824f987ce599"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 19628  100 19628    0     0   242k      0 --:--:-- --:--:-- --:--:--  242k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 14747  100 14747    0     0   155k      0 --:--:-- --:--:-- --:--:--  156k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 13888  100 13888    0     0   171k      0 --:--:-- --:--:-- --:--:--  171k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 15109  100 15109    0     0   146k      0 --:--:-- --:--:-- --:--:--  147k\n"
=======
            "--2025-02-24 18:45:59--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw1.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19628 (19K) [text/plain]\n",
            "Saving to: â€˜john_wick_1.csvâ€™\n",
            "\n",
            "john_wick_1.csv     100%[===================>]  19.17K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2025-02-24 18:45:59 (1.41 MB/s) - â€˜john_wick_1.csvâ€™ saved [19628/19628]\n",
            "\n",
            "--2025-02-24 18:45:59--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw2.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14747 (14K) [text/plain]\n",
            "Saving to: â€˜john_wick_2.csvâ€™\n",
            "\n",
            "john_wick_2.csv     100%[===================>]  14.40K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2025-02-24 18:46:00 (2.25 MB/s) - â€˜john_wick_2.csvâ€™ saved [14747/14747]\n",
            "\n",
            "--2025-02-24 18:46:00--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw3.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13888 (14K) [text/plain]\n",
            "Saving to: â€˜john_wick_3.csvâ€™\n",
            "\n",
            "john_wick_3.csv     100%[===================>]  13.56K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2025-02-24 18:46:00 (1.98 MB/s) - â€˜john_wick_3.csvâ€™ saved [13888/13888]\n",
            "\n",
            "--2025-02-24 18:46:01--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw4.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15109 (15K) [text/plain]\n",
            "Saving to: â€˜john_wick_4.csvâ€™\n",
            "\n",
            "john_wick_4.csv     100%[===================>]  14.75K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2025-02-24 18:46:01 (2.58 MB/s) - â€˜john_wick_4.csvâ€™ saved [15109/15109]\n",
            "\n"
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
          ]
        }
      ],
      "source": [
<<<<<<< HEAD
        "!curl \"https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw1.csv\" -o john_wick_1.csv\n",
        "!curl \"https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw2.csv\" -o john_wick_2.csv\n",
        "!curl \"https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw3.csv\" -o john_wick_3.csv\n",
        "!curl \"https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw4.csv\" -o john_wick_4.csv"
=======
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw1.csv -O john_wick_1.csv\n",
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw2.csv -O john_wick_2.csv\n",
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw3.csv -O john_wick_3.csv\n",
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw4.csv -O john_wick_4.csv"
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A92NC2QZzCsi"
      },
      "source": [
        "### Data Preparation\n",
        "\n",
        "We want to make sure all our documents have the relevant metadata for the various retrieval strategies we're going to be applying today.\n",
        "\n",
        "- Self-Query: Wants as much metadata as we can provide\n",
        "- Time-weighted: Wants temporal data\n",
        "\n",
        "> NOTE: While we're creating a temporal relationship based on when these movies came out for illustrative purposes, it needs to be clear that the \"time-weighting\" in the Time-weighted Retriever is based on when the document was *accessed* last - not when it was created."
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 9,
=======
      "execution_count": 4,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
      "metadata": {
        "id": "GshBjVRJZ6p8"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "documents = []\n",
        "\n",
        "for i in range(1, 5):\n",
        "  loader = CSVLoader(\n",
        "      file_path=f\"john_wick_{i}.csv\",\n",
        "      metadata_columns=[\"Review_Date\", \"Review_Title\", \"Review_Url\", \"Author\", \"Rating\"]\n",
        "  )\n",
        "\n",
        "  movie_docs = loader.load()\n",
        "  for doc in movie_docs:\n",
        "\n",
        "    # Add the \"Movie Title\" (John Wick 1, 2, ...)\n",
        "    doc.metadata[\"Movie_Title\"] = f\"John Wick {i}\"\n",
        "\n",
        "    # convert \"Rating\" to an `int`, if no rating is provided - assume 0 rating\n",
        "    doc.metadata[\"Rating\"] = int(doc.metadata[\"Rating\"]) if doc.metadata[\"Rating\"] else 0\n",
        "\n",
        "    # newer movies have a more recent \"last_accessed_at\"\n",
        "    doc.metadata[\"last_accessed_at\"] = datetime.now() - timedelta(days=4-i)\n",
        "\n",
        "  documents.extend(movie_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gQphb6y0C0S"
      },
      "source": [
        "Let's look at an example document to see if everything worked as expected!"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 10,
=======
      "execution_count": 5,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkUkCf7DaMiq",
        "outputId": "e90bd5da-1d87-423b-838a-cb6efc16b199"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
<<<<<<< HEAD
              "Document(metadata={'source': 'john_wick_1.csv', 'row': 0, 'Review_Date': '6 May 2015', 'Review_Title': ' Kinetic, concise, and stylish; John Wick kicks ass.\\n', 'Review_Url': '/review/rw3233896/?ref_=tt_urv', 'Author': 'lnvicta', 'Rating': 8, 'Movie_Title': 'John Wick 1', 'last_accessed_at': datetime.datetime(2025, 5, 17, 9, 56, 53, 38254)}, page_content=\": 0\\nReview: The best way I can describe John Wick is to picture Taken but instead of Liam Neeson it's Keanu Reeves and instead of his daughter it's his dog. That's essentially the plot of the movie. John Wick (Reeves) is out to seek revenge on the people who took something he loved from him. It's a beautifully simple premise for an action movie - when action movies get convoluted, they get bad i.e. A Good Day to Die Hard. John Wick gives the viewers what they want: Awesome action, stylish stunts, kinetic chaos, and a relatable hero to tie it all together. John Wick succeeds in its simplicity.\")"
            ]
          },
          "execution_count": 10,
=======
              "Document(metadata={'source': 'john_wick_1.csv', 'row': 0, 'Review_Date': '6 May 2015', 'Review_Title': ' Kinetic, concise, and stylish; John Wick kicks ass.\\n', 'Review_Url': '/review/rw3233896/?ref_=tt_urv', 'Author': 'lnvicta', 'Rating': 8, 'Movie_Title': 'John Wick 1', 'last_accessed_at': datetime.datetime(2025, 2, 21, 18, 46, 5, 58301)}, page_content=\": 0\\nReview: The best way I can describe John Wick is to picture Taken but instead of Liam Neeson it's Keanu Reeves and instead of his daughter it's his dog. That's essentially the plot of the movie. John Wick (Reeves) is out to seek revenge on the people who took something he loved from him. It's a beautifully simple premise for an action movie - when action movies get convoluted, they get bad i.e. A Good Day to Die Hard. John Wick gives the viewers what they want: Awesome action, stylish stunts, kinetic chaos, and a relatable hero to tie it all together. John Wick succeeds in its simplicity.\")"
            ]
          },
          "execution_count": 5,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "documents[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWaQpdHl0Gzc"
      },
      "source": [
        "## Task 3: Setting up QDrant!\n",
        "\n",
        "Now that we have our documents, let's create a QDrant VectorStore with the collection name \"JohnWick\".\n",
        "\n",
        "We'll leverage OpenAI's [`text-embedding-3-small`](https://openai.com/blog/new-embedding-models-and-api-updates) because it's a very powerful (and low-cost) embedding model.\n",
        "\n",
        "> NOTE: We'll be creating additional vectorstores where necessary, but this pattern is still extremely useful."
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 11,
      "metadata": {
        "id": "NT8ihRJbYmMT"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/cantemizyurek/Documents/code/ai/ai-maker-space/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/qdrant_client/http/models/models.py:758: SyntaxWarning: invalid escape sequence '\\&'\n",
            "  description=\"Check that the field is empty, alternative syntax for `is_empty: \\&quot;field_name\\&quot;`\",\n",
            "/Users/cantemizyurek/Documents/code/ai/ai-maker-space/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/qdrant_client/http/models/models.py:762: SyntaxWarning: invalid escape sequence '\\&'\n",
            "  description=\"Check that the field is null, alternative syntax for `is_null: \\&quot;field_name\\&quot;`\",\n"
          ]
        }
      ],
=======
      "execution_count": 6,
      "metadata": {
        "id": "NT8ihRJbYmMT"
      },
      "outputs": [],
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
      "source": [
        "from langchain_community.vectorstores import Qdrant\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "\n",
        "vectorstore = Qdrant.from_documents(\n",
        "    documents,\n",
        "    embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"JohnWick\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-x2SS4Rh0hiN"
      },
      "source": [
        "## Task 4: Naive RAG Chain\n",
        "\n",
        "Since we're focusing on the \"R\" in RAG today - we'll create our Retriever first."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEH7X5Ai08FH"
      },
      "source": [
        "### R - Retrieval\n",
        "\n",
        "This naive retriever will simply look at each review as a document, and use cosine-similarity to fetch the 10 most relevant documents.\n",
        "\n",
        "> NOTE: We're choosing `10` as our `k` here to provide enough documents for our reranking process later"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 12,
=======
      "execution_count": 7,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
      "metadata": {
        "id": "GFDPrNBtb72o"
      },
      "outputs": [],
      "source": [
        "naive_retriever = vectorstore.as_retriever(search_kwargs={\"k\" : 10})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbBhyQjz06dx"
      },
      "source": [
        "### A - Augmented\n",
        "\n",
        "We're going to go with a standard prompt for our simple RAG chain today! Nothing fancy here, we want this to mostly be about the Retrieval process."
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 13,
=======
      "execution_count": 8,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
      "metadata": {
        "id": "7uSz-Dbqcoki"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "RAG_TEMPLATE = \"\"\"\\\n",
        "You are a helpful and kind assistant. Use the context provided below to answer the question.\n",
        "\n",
        "If you do not know the answer, or are unsure, say you don't know.\n",
        "\n",
        "Query:\n",
        "{question}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "rag_prompt = ChatPromptTemplate.from_template(RAG_TEMPLATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlRzpb231GGJ"
      },
      "source": [
        "### G - Generation\n",
        "\n",
        "We're going to leverage `gpt-4.1-nano` as our LLM today, as - again - we want this to largely be about the Retrieval process."
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 18,
=======
      "execution_count": 9,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
      "metadata": {
        "id": "c-1t9H60dJLg"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
<<<<<<< HEAD
        "chat_model = ChatOpenAI(model_name=\"gpt-4.1-nano\")\n"
=======
        "chat_model = ChatOpenAI(\"gpt-4.1-nano\")\n"
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mg3QRGzA1M2x"
      },
      "source": [
        "### LCEL RAG Chain\n",
        "\n",
        "We're going to use LCEL to construct our chain.\n",
        "\n",
        "> NOTE: This chain will be exactly the same across the various examples with the exception of our Retriever!"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 19,
=======
      "execution_count": 10,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
      "metadata": {
        "id": "0bvstS7mdOW3"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from operator import itemgetter\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "naive_retrieval_chain = (\n",
        "    # INVOKE CHAIN WITH: {\"question\" : \"<<SOME USER QUESTION>>\"}\n",
        "    # \"question\" : populated by getting the value of the \"question\" key\n",
        "    # \"context\"  : populated by getting the value of the \"question\" key and chaining it into the base_retriever\n",
        "    {\"context\": itemgetter(\"question\") | naive_retriever, \"question\": itemgetter(\"question\")}\n",
        "    # \"context\"  : is assigned to a RunnablePassthrough object (will not be called or considered in the next step)\n",
        "    #              by getting the value of the \"context\" key from the previous step\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    # \"response\" : the \"context\" and \"question\" values are used to format our prompt object and then piped\n",
        "    #              into the LLM and stored in a key called \"response\"\n",
        "    # \"context\"  : populated by getting the value of the \"context\" key from the previous step\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izKujhNb1ZG8"
      },
      "source": [
        "Let's see how this simple chain does on a few different prompts.\n",
        "\n",
        "> NOTE: You might think that we've cherry picked prompts that showcase the individual skill of each of the retrieval strategies - you'd be correct!"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 20,
=======
      "execution_count": 11,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "LI-5ueEddku9",
        "outputId": "7f3cec18-5f4e-41bb-cf71-51ba0be5388e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
<<<<<<< HEAD
              "'Based on the reviews provided, people generally liked John Wick. Several reviews gave high ratings (such as 8, 9, and 10 out of 10), praising its action sequences, style, and entertainment value. While some individuals were more critical and gave lower ratings, the overall sentiment leans towards appreciation and enjoyment of the film series.'"
            ]
          },
          "execution_count": 20,
=======
              "'Yes, people generally liked John Wick based on the reviews provided.'"
            ]
          },
          "execution_count": 11,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 21,
=======
      "execution_count": 12,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "43zdcdUydtXh",
        "outputId": "db874e67-f568-4ed1-b863-b7c17b387052"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
<<<<<<< HEAD
              "'Yes, there are reviews with a rating of 10. The URLs to those reviews are:\\n\\n- [Review of John Wick 3](https://example.com/review/rw4854296/?ref_=tt_urv) (Review URL: /review/rw4854296/?ref_=tt_urv)'"
            ]
          },
          "execution_count": 21,
=======
              "\"Yes, there is a review with a rating of 10. Here is the URL to that review: '/review/rw4854296/?ref_=tt_urv'\""
            ]
          },
          "execution_count": 12,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 22,
=======
      "execution_count": 13,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "lpG6rlvvvKFq",
        "outputId": "a1b330b0-628e-41be-d829-9c1d55e781f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
<<<<<<< HEAD
              "\"In the John Wick movies, the story centers around John Wick, a retired hitman who is exceptionally skilled and lethal. The series begins with Wick mourning the loss of his wife and trying to rebuild his life. His peace is shattered when a gang of criminals, including a young Russian punk and his associates, attack him, kill his dog (which was a gift from his wife), and steal his car. This act of violence pulls Wick back into the violent underworld he had left behind.\\n\\nThroughout the series, Wick seeks revenge against those who have wronged him and navigates a complex world of assassins, mobsters, and strict criminal rules. His actions lead to widespread chaos, and he becomes a target of numerous hitmen and criminal organizations, with a hefty bounty placed on his head. Wick's journey involves intense action sequences, revenge, and the unraveling of his carefully concealed past as a legendary assassin.\\n\\nOverall, the films depict a highly stylized, action-packed universe with themes of vengeance, consequences, and survival.\""
            ]
          },
          "execution_count": 22,
=======
              "'In John Wick, the story follows the character of John Wick, an ex-hit-man who comes out of retirement to seek vengeance after gangsters kill his dog and steal everything from him. This leads to a series of violent confrontations and action-packed sequences as John Wick goes after those responsible for his loss.'"
            ]
          },
          "execution_count": 13,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsbfQmbr1leg"
      },
      "source": [
        "Overall, this is not bad! Let's see if we can make it better!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ft1vt8HPR16w"
      },
      "source": [
        "## Task 5: Best-Matching 25 (BM25) Retriever\n",
        "\n",
        "Taking a step back in time - [BM25](https://www.nowpublishers.com/article/Details/INR-019) is based on [Bag-Of-Words](https://en.wikipedia.org/wiki/Bag-of-words_model) which is a sparse representation of text.\n",
        "\n",
        "In essence, it's a way to compare how similar two pieces of text are based on the words they both contain.\n",
        "\n",
        "This retriever is very straightforward to set-up! Let's see it happen down below!\n"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 23,
=======
      "execution_count": 14,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
      "metadata": {
        "id": "qdF4wuj5R-cG"
      },
      "outputs": [],
      "source": [
        "from langchain_community.retrievers import BM25Retriever\n",
        "\n",
        "bm25_retriever = BM25Retriever.from_documents(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIjJlBQ8drKH"
      },
      "source": [
        "We'll construct the same chain - only changing the retriever."
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 24,
=======
      "execution_count": null,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
      "metadata": {
        "id": "WR15EQG7SLuw"
      },
      "outputs": [],
      "source": [
        "bm25_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | bm25_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Gi-yXCDdvJk"
      },
      "source": [
        "Let's look at the responses!"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 25,
=======
      "execution_count": null,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "oY9qzmm3SOrF",
        "outputId": "4d4f450f-5978-460f-f242-b32407868353"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
<<<<<<< HEAD
              "\"Based on the reviews provided, people's opinions on John Wick are mixed. Some viewers, like IceSkateUpHill and lnvicta, highly appreciated the film, praising its action sequences and stylish execution. However, others, such as Phil_H and janetwilkinson, had negative opinions, criticizing the plot and violence. Overall, it appears that some people generally liked John Wick, but many were also critical of certain aspects.\""
            ]
          },
          "execution_count": 25,
=======
              "'Opinions on John Wick seem to be varied. Some people really enjoy the movie, appreciating its action sequences, stylish stunts, and the character of John Wick himself. Others, however, find it lacking in plot and substance, with excessive violence and repetitive elements. Overall, it seems that the reception to John Wick is mixed among viewers.'"
            ]
          },
          "execution_count": 17,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 26,
=======
      "execution_count": null,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "igfinyneSQkh",
        "outputId": "9752d4a9-dd16-45b1-f63f-a76e93a05eb3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
<<<<<<< HEAD
              "'Based on the provided reviews, there are no reviews with a rating of 10.'"
            ]
          },
          "execution_count": 26,
=======
              "'Yes, there is a review with a rating of 10 for the movie \"John Wick 4\" by the author jtindahouse. Here is the URL to that review: \\'/review/rw8946038/?ref_=tt_urv\\'.'"
            ]
          },
          "execution_count": 18,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 27,
=======
      "execution_count": null,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "w0H7pV_USSMQ",
        "outputId": "bdead654-3109-4143-9a30-e1d6ca8dc534"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
<<<<<<< HEAD
              "'In the John Wick movies, the story centers around a former hitman named John Wick who seeks to avenge the loss of his beloved dog and reclaim his life after a series of violent events. The films depict his intense and highly choreographed battles against various assassin organizations and enemies. Overall, the movies showcase a mix of emotional depth, brutal action, and intricate choreography.'"
            ]
          },
          "execution_count": 27,
=======
              "'John Wick is a movie known for its beautifully choreographed action scenes and emotional setup. It stars Keanu Reeves and is highly recommended for action movie fans.'"
            ]
          },
          "execution_count": 19,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvg5xHaUdxCl"
      },
      "source": [
        "It's not clear that this is better or worse - but the `I don't know` isn't great!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-dcbFn2vpZF"
      },
      "source": [
        "## Task 6: Contextual Compression (Using Reranking)\n",
        "\n",
        "Contextual Compression is a fairly straightforward idea: We want to \"compress\" our retrieved context into just the most useful bits.\n",
        "\n",
        "There are a few ways we can achieve this - but we're going to look at a specific example called reranking.\n",
        "\n",
        "The basic idea here is this:\n",
        "\n",
        "- We retrieve lots of documents that are very likely related to our query vector\n",
        "- We \"compress\" those documents into a smaller set of *more* related documents using a reranking algorithm.\n",
        "\n",
        "We'll be leveraging Cohere's Rerank model for our reranker today!\n",
        "\n",
        "All we need to do is the following:\n",
        "\n",
        "- Create a basic retriever\n",
        "- Create a compressor (reranker, in this case)\n",
        "\n",
        "That's it!\n",
        "\n",
        "Let's see it in the code below!"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 28,
=======
      "execution_count": 20,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
      "metadata": {
        "id": "psHvO2K1v_ZQ"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
        "from langchain_cohere import CohereRerank\n",
        "\n",
        "compressor = CohereRerank(model=\"rerank-english-v3.0\")\n",
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor, base_retriever=naive_retriever\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TA9RB2x-j7P"
      },
      "source": [
        "Let's create our chain again, and see how this does!"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 29,
=======
      "execution_count": 21,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
      "metadata": {
        "id": "1BXqmxvHwX6T"
      },
      "outputs": [],
      "source": [
        "contextual_compression_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | compression_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 30,
=======
      "execution_count": 22,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "V3iGpokswcBb",
        "outputId": "f15d2aa1-5e8b-417d-f623-eb835d072e59"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
<<<<<<< HEAD
              "'Based on the reviews provided, people generally liked John Wick. The film received high ratings, such as 9 and 10 out of 10, and the reviews are very positive, describing it as a slick, fun, and well-choreographed action film that is highly entertaining. However, there was some criticism of later installments, like John Wick 3, which received a more mixed review with a rating of 5, indicating that some viewers felt the magic was gone. Overall, the initial reception suggests that most people enjoyed the original John Wick movie.'"
            ]
          },
          "execution_count": 30,
=======
              "\"Based on the reviews provided, it seems like people generally really liked John Wick. The reviews praise the film for its slickness, brilliance in action sequences, Keanu Reeves' performance, and overall entertainment value.\""
            ]
          },
          "execution_count": 22,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 31,
=======
      "execution_count": 23,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "7u_k0i4OweUd",
        "outputId": "be5fccc8-2352-4189-c524-bbeaa28cf799"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
<<<<<<< HEAD
              "'Yes, there are reviews with a rating of 10. Here are the URLs to those reviews:\\n\\n1. [Review about John Wick 3 titled \"A Masterpiece & Brilliant Sequel\"]( /review/rw4854296/?ref_=tt_urv )\\n2. [Review about John Wick 4 titled \"How Can Anyone Choose to Watch Marvel Over This?\"]( /review/rw8944843/?ref_=tt_urv )\\n3. [Another review about John Wick 3 titled \"It\\'s got its own action style!\"]( /review/rw4860412/?ref_=tt_urv )\\n\\nPlease let me know if you need any further assistance!'"
            ]
          },
          "execution_count": 31,
=======
              "'Yes, there is a review with a rating of 10. Here is the URL to that review:\\n- Review URL: /review/rw4854296/?ref_=tt_urv'"
            ]
          },
          "execution_count": 23,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 32,
=======
      "execution_count": 27,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "zn1EqaGqweXN",
        "outputId": "42bc5972-4164-46eb-f49d-4272f39bb89b"
      },
      "outputs": [
        {
          "data": {
<<<<<<< HEAD
            "text/plain": [
              "\"In the John Wick films, John Wick (played by Keanu Reeves) is a retired hitman who seeks vengeance after a series of tragic events. In the first movie, his beloved dog is killed, and his car is stolen, prompting him to come out of retirement to hunt down those responsible. The story involves his return to the violent underworld, encounters with dangerous criminals, and his efforts to protect himself and those he cares about. In the second film, John Wick faces new challenges when a former associate, Santino D'Antonio, asks for his help to eliminate his sister so he can sit on the criminal High Table. After completing the mission, John Wick becomes the target of a huge bounty and must navigate this dangerous world to survive. Overall, the series features intense action, revenge, and stylish fight scenes.\""
            ]
          },
          "execution_count": 32,
=======
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"In John Wick, after resolving his issues with the Russian mafia, John Wick is forced back into action when mobster Santino D'Antonio asks him to kill his sister in Rome. When Wick completes the task, Santino puts a bounty on him, leading to professional killers coming after him. Wick then seeks revenge on Santino.\""
            ]
          },
          "execution_count": 27,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEbT0g2S-mZ4"
      },
      "source": [
        "We'll need to rely on something like Ragas to help us get a better sense of how this is performing overall - but it \"feels\" better!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqbghrBEQNn5"
      },
      "source": [
        "## Task 7: Multi-Query Retriever\n",
        "\n",
        "Typically in RAG we have a single query - the one provided by the user.\n",
        "\n",
        "What if we had....more than one query!\n",
        "\n",
        "In essence, a Multi-Query Retriever works by:\n",
        "\n",
        "1. Taking the original user query and creating `n` number of new user queries using an LLM.\n",
        "2. Retrieving documents for each query.\n",
        "3. Using all unique retrieved documents as context\n",
        "\n",
        "So, how is it to set-up? Not bad! Let's see it down below!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 33,
=======
      "execution_count": 24,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
      "metadata": {
        "id": "pfM26ReXQjzU"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "\n",
        "multi_query_retriever = MultiQueryRetriever.from_llm(\n",
        "    retriever=naive_retriever, llm=chat_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 34,
=======
      "execution_count": 25,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
      "metadata": {
        "id": "1vRc129jQ5WW"
      },
      "outputs": [],
      "source": [
        "multi_query_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | multi_query_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 35,
=======
      "execution_count": 26,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "CGgNuOb3Q3M9",
        "outputId": "c5273ecf-da35-40b8-fbdb-0f8beab425f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
<<<<<<< HEAD
              "'Based on the reviews provided, people generally liked John Wick. Several reviews rate the film highly, praising its action sequences, style, and entertainment value, with some giving ratings like 9 or 10 out of 10. There are a few mixed or negative reviews, but overall, the majority of reviews indicate that audiences appreciated the film.'"
            ]
          },
          "execution_count": 35,
=======
              "'Yes, people generally liked John Wick based on the positive reviews provided.'"
            ]
          },
          "execution_count": 26,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 36,
=======
      "execution_count": 27,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "aAlSthxrRDBC",
        "outputId": "230ff807-23ae-4d25-8d11-cfdbed0b77cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
<<<<<<< HEAD
              "'Yes, there is a review with a rating of 10. The URL to that review is: /review/rw4854296/?ref_=tt_urv'"
            ]
          },
          "execution_count": 36,
=======
              "\"I'm sorry, there are no reviews with a rating of 10 in the provided context.\""
            ]
          },
          "execution_count": 27,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 37,
=======
      "execution_count": 28,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "Uv1mpCK8REs4",
        "outputId": "00fbc22a-ed9b-4613-9695-0b179e3f8369"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
<<<<<<< HEAD
              "'In the John Wick movies, Keanu Reeves plays John Wick, a retired assassin who is drawn back into a world of violence and revenge. The series begins with John Wick seeking vengeance after his dog, a gift from his late wife, is murdered, and his car is stolen. Throughout the films, he is depicted as a highly skilled and formidable killer who faces various enemies from the criminal underworld. The story involves complex criminal organizations, a strict code of conduct, and intense action sequences as Wick fights to protect himself and uphold his own sense of honor. The series expands on his past as an assassin, revealing a world filled with dangerous allies and deadly foes, with themes of revenge, consequence, and redemption.'"
            ]
          },
          "execution_count": 37,
=======
              "\"In John Wick, the story follows a retired assassin named John Wick who comes out of retirement after someone kills his dog and steals his car, leading to a lot of carnage. He is then called on to pay off an old debt by helping take over the Assassin's Guild by traveling to Italy, Canada, and Manhattan to eliminate numerous assassins.\""
            ]
          },
          "execution_count": 28,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDEawBf_d_3G"
      },
      "source": [
        "## Task 8: Parent Document Retriever\n",
        "\n",
        "A \"small-to-big\" strategy - the Parent Document Retriever works based on a simple strategy:\n",
        "\n",
        "1. Each un-split \"document\" will be designated as a \"parent document\" (You could use larger chunks of document as well, but our data format allows us to consider the overall document as the parent chunk)\n",
        "2. Store those \"parent documents\" in a memory store (not a VectorStore)\n",
        "3. We will chunk each of those documents into smaller documents, and associate them with their respective parents, and store those in a VectorStore. We'll call those \"child chunks\".\n",
        "4. When we query our Retriever, we will do a similarity search comparing our query vector to the \"child chunks\".\n",
        "5. Instead of returning the \"child chunks\", we'll return their associated \"parent chunks\".\n",
        "\n",
        "Okay, maybe that was a few steps - but the basic idea is this:\n",
        "\n",
        "- Search for small documents\n",
        "- Return big documents\n",
        "\n",
        "The intuition is that we're likely to find the most relevant information by limiting the amount of semantic information that is encoded in each embedding vector - but we're likely to miss relevant surrounding context if we only use that information.\n",
        "\n",
        "Let's start by creating our \"parent documents\" and defining a `RecursiveCharacterTextSplitter`."
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 38,
=======
      "execution_count": 29,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
      "metadata": {
        "id": "qJ53JJuMd_ZH"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import ParentDocumentRetriever\n",
        "from langchain.storage import InMemoryStore\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from qdrant_client import QdrantClient, models\n",
        "\n",
        "parent_docs = documents\n",
        "child_splitter = RecursiveCharacterTextSplitter(chunk_size=200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOpXfVUH3gL3"
      },
      "source": [
        "We'll need to set up a new QDrant vectorstore - and we'll use another useful pattern to do so!\n",
        "\n",
        "> NOTE: We are manually defining our embedding dimension, you'll need to change this if you're using a different embedding model."
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 39,
=======
      "execution_count": 30,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzFc-_9HlGQ-",
        "outputId": "223662dd-c36f-42f7-d1b0-b086e571484e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "/var/folders/4g/z7lg2sn54psdscz7n3229t6c0000gn/T/ipykernel_34256/3574430551.py:8: LangChainDeprecationWarning: The class `Qdrant` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-qdrant package and should be used instead. To use it run `pip install -U :class:`~langchain-qdrant` and import as `from :class:`~langchain_qdrant import Qdrant``.\n",
=======
            "/tmp/ipykernel_1031530/3574430551.py:8: LangChainDeprecationWarning: The class `Qdrant` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-qdrant package and should be used instead. To use it run `pip install -U :class:`~langchain-qdrant` and import as `from :class:`~langchain_qdrant import Qdrant``.\n",
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
            "  parent_document_vectorstore = Qdrant(\n"
          ]
        }
      ],
      "source": [
        "client = QdrantClient(location=\":memory:\")\n",
        "\n",
        "client.create_collection(\n",
        "    collection_name=\"full_documents\",\n",
        "    vectors_config=models.VectorParams(size=1536, distance=models.Distance.COSINE)\n",
        ")\n",
        "\n",
        "parent_document_vectorstore = Qdrant(\n",
        "    collection_name=\"full_documents\", embeddings=OpenAIEmbeddings(model=\"text-embedding-3-small\"), client=client\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sf_g95FA3s6w"
      },
      "source": [
        "Now we can create our `InMemoryStore` that will hold our \"parent documents\" - and build our retriever!"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 40,
=======
      "execution_count": 31,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
      "metadata": {
        "id": "BpWVjPf4fLUp"
      },
      "outputs": [],
      "source": [
        "store = InMemoryStore()\n",
        "\n",
        "parent_document_retriever = ParentDocumentRetriever(\n",
        "    vectorstore = parent_document_vectorstore,\n",
        "    docstore=store,\n",
        "    child_splitter=child_splitter,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoYmSWfE32Zo"
      },
      "source": [
        "By default, this is empty as we haven't added any documents - let's add some now!"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 41,
=======
      "execution_count": 32,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
      "metadata": {
        "id": "iQ2ZzfKigMZc"
      },
      "outputs": [],
      "source": [
        "parent_document_retriever.add_documents(parent_docs, ids=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI7Tip1335rE"
      },
      "source": [
        "We'll create the same chain we did before - but substitute our new `parent_document_retriever`."
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 42,
=======
      "execution_count": 33,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
      "metadata": {
        "id": "Qq_adt2KlSqp"
      },
      "outputs": [],
      "source": [
        "parent_document_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | parent_document_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNolUVQb4Apt"
      },
      "source": [
        "Let's give it a whirl!"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 43,
=======
      "execution_count": 34,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "TXB5i89Zly5W",
        "outputId": "94c240be-7c5b-4c58-9eee-56d93285a054"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
<<<<<<< HEAD
              "'Based on the provided reviews, people\\'s opinions on John Wick vary. Some reviewers, like MrHeraclius, highly recommend the series and praise it highly, indicating they liked the movies. Conversely, a review from solidabs gives a very negative opinion of John Wick 4, calling it \"HORRIBLE\" and criticizing its plot and fight scenes, though this reviewer still mentions loving the series overall. Overall, it seems that many fans appreciate the series, but there are also some negative opinions. Therefore, people did not generally have a uniform opinion; some liked it while others did not.'"
            ]
          },
          "execution_count": 43,
=======
              "'Based on the reviews provided, opinions about John Wick seem to be divided. Some people like the series, while others have strong negative opinions about it.'"
            ]
          },
          "execution_count": 34,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 44,
=======
      "execution_count": 35,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "V5F1T-wNl3cg",
        "outputId": "9b81e72e-5db7-4b8a-b25b-400ea0df5335"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
<<<<<<< HEAD
              "'Yes, there is a review with a rating of 10. The URL to that review is: /review/rw4854296/?ref_=tt_urv'"
            ]
          },
          "execution_count": 44,
=======
              "'Yes, there is a review with a rating of 10. Here is the URL to that review: /review/rw4854296/?ref_=tt_urv'"
            ]
          },
          "execution_count": 35,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 45,
=======
      "execution_count": 36,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "ZqARszGzvGcG",
        "outputId": "8867f83c-db13-4db4-d57f-9bd51d32cd8a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
<<<<<<< HEAD
              "\"In the John Wick series, John Wick is a retired assassin who is drawn back into a world of violence and revenge. In the first movie, John seeks vengeance after his dog is killed and his car is stolen, leading him to unleash a relentless and deadly campaign against gangsters and assassins. The second film continues his story, where he is obliged to help an old acquaintance take over the Assassin's Guild, which involves traveling across locations like Italy, Canada, and Manhattan, and fighting numerous assassins along the way. Overall, John's actions result in a lot of carnage and showcase his lethal skills.\""
            ]
          },
          "execution_count": 45,
=======
              "\"In John Wick, John Wick is a retired assassin who comes out of retirement to seek revenge after someone kills his dog and steals his car. He is then called on to pay off an old debt by helping Ian McShane take over the Assassin's Guild by flying around to Italy, Canada, and Manhattan and killing numerous assassins.\""
            ]
          },
          "execution_count": 36,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B41cj42s4DPM"
      },
      "source": [
        "Overall, the performance *seems* largely the same. We can leverage a tool like [Ragas]() to more effectively answer the question about the performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUrIBKl_TwS9"
      },
      "source": [
        "## Task 9: Ensemble Retriever\n",
        "\n",
        "In brief, an Ensemble Retriever simply takes 2, or more, retrievers and combines their retrieved documents based on a rank-fusion algorithm.\n",
        "\n",
        "In this case - we're using the [Reciprocal Rank Fusion](https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf) algorithm.\n",
        "\n",
        "Setting it up is as easy as providing a list of our desired retrievers - and the weights for each retriever."
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 46,
=======
      "execution_count": 37,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
      "metadata": {
        "id": "8j7jpZsKTxic"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import EnsembleRetriever\n",
        "\n",
        "retriever_list = [bm25_retriever, naive_retriever, parent_document_retriever, compression_retriever, multi_query_retriever]\n",
        "equal_weighting = [1/len(retriever_list)] * len(retriever_list)\n",
        "\n",
        "ensemble_retriever = EnsembleRetriever(\n",
        "    retrievers=retriever_list, weights=equal_weighting\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpo9Psl5hhJ-"
      },
      "source": [
        "We'll pack *all* of these retrievers together in an ensemble."
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 47,
=======
      "execution_count": 38,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
      "metadata": {
        "id": "KZ__EZwpUKkd"
      },
      "outputs": [],
      "source": [
        "ensemble_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | ensemble_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSsvHpRMj24L"
      },
      "source": [
        "Let's look at our results!"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 48,
=======
      "execution_count": 39,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "0lMvqL88UQI-",
        "outputId": "d86dd5f7-0a13-4836-c0ce-cc4c431fd889"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
<<<<<<< HEAD
              "'Based on the reviews provided, people generally liked John Wick. Many reviews give high ratings (such as 8 or 9 out of 10) and describe the films as stylish, fun, intense, and well-choreographed. However, there are some negative opinions as well, with a few reviewers giving low ratings (around 1 to 3) and expressing discontent with the plot, length, or perceived silliness of the movies. Overall, the majority of reviews are positive, indicating that people generally enjoyed John Wick.'"
            ]
          },
          "execution_count": 48,
=======
              "\"Based on the reviews provided, it seems that the majority of people generally liked John Wick. The action sequences, Keanu Reeves' performance, and the overall style of the movie were well-received by many reviewers. However, there were some negative reviews from individuals who did not enjoy the film due to its violence or lack of plot. Overall, the general sentiment appears to be positive towards John Wick.\""
            ]
          },
          "execution_count": 39,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 49,
=======
      "execution_count": 40,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "MNFWLYECURI1",
        "outputId": "b17973b5-66a9-4481-97d5-880b5754b5c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
<<<<<<< HEAD
              "'Yes, there are reviews with a rating of 10. The URLs to those reviews are:\\n\\n1. [John Wick 3 Review](https://example.com/review/rw4854296/?ref_=tt_urv)\\n2. [John Wick 4 Review](https://example.com/review/rw8944843/?ref_=tt_urv)\\n\\nPlease note that the exact URLs are taken from the relevant review entries provided in the context.'"
            ]
          },
          "execution_count": 49,
=======
              "\"Yes, there is one review with a rating of 10. Here is the URL to that review: '/review/rw4854296/?ref_=tt_urv'\""
            ]
          },
          "execution_count": 40,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 50,
=======
      "execution_count": 41,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "A7qbHfWgUR4c",
        "outputId": "f7373144-59ef-4fc7-b75d-ca00e7df881e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
<<<<<<< HEAD
              "'In the John Wick series, the story centers around John Wick, a retired assassin who is drawn back into a violent underworld of crime and retribution. The first film depicts how Wick comes out of retirement to avenge the killing of his dog and the theft of his car, uncovering a brutal world of assassins and criminal organizations. Subsequent films follow his ongoing conflicts with the criminal underworld, as he is targeted by bounty hunters and mobsters, and struggles with moral choices and consequences of his violent actions. The franchise is renowned for its stylish, choreographed action sequences and deepening exploration of its fictional universe.'"
            ]
          },
          "execution_count": 50,
=======
              "'John Wick is an action-packed movie series that follows the story of a retired hitman, John Wick, who seeks vengeance after gangsters kill his dog and steal his car. This leads to a series of violent confrontations with various enemies throughout the movies.'"
            ]
          },
          "execution_count": 41,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MopbkNJAXVaN"
      },
      "source": [
        "## Task 10: Semantic Chunking\n",
        "\n",
        "While this is not a retrieval method - it *is* an effective way of increasing retrieval performance on corpora that have clean semantic breaks in them.\n",
        "\n",
        "Essentially, Semantic Chunking is implemented by:\n",
        "\n",
        "1. Embedding all sentences in the corpus.\n",
        "2. Combining or splitting sequences of sentences based on their semantic similarity based on a number of [possible thresholding methods](https://python.langchain.com/docs/how_to/semantic-chunker/):\n",
        "  - `percentile`\n",
        "  - `standard_deviation`\n",
        "  - `interquartile`\n",
        "  - `gradient`\n",
        "3. Each sequence of related sentences is kept as a document!\n",
        "\n",
        "Let's see how to implement this!\n",
        "\n",
        "> NOTE: You do not need to run this cell if you're running this locally"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dHeB-yGXneL",
        "outputId": "efc59105-518a-4134-9228-d98b8a97e08e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m208.1/208.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m399.9/399.9 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m292.1/292.1 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "#!pip install -qU langchain_experimental"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9ciZbFEldv_"
      },
      "source": [
        "We'll use the `percentile` thresholding method for this example which will:\n",
        "\n",
        "Calculate all distances between sentences, and then break apart sequences of setences that exceed a given percentile among all distances."
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 51,
=======
      "execution_count": 42,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
      "metadata": {
        "id": "66EIEWiEYl5y"
      },
      "outputs": [],
      "source": [
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "\n",
        "semantic_chunker = SemanticChunker(\n",
        "    embeddings,\n",
        "    breakpoint_threshold_type=\"percentile\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqoKmz12mhRW"
      },
      "source": [
        "Now we can split our documents."
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 52,
=======
      "execution_count": 43,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
      "metadata": {
        "id": "ROcV7o68ZIq7"
      },
      "outputs": [],
      "source": [
        "semantic_documents = semantic_chunker.split_documents(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8-LNC-Xmjex"
      },
      "source": [
        "Let's create a new vector store."
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 53,
=======
      "execution_count": 44,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
      "metadata": {
        "id": "h3sl9QjyZhIe"
      },
      "outputs": [],
      "source": [
        "semantic_vectorstore = Qdrant.from_documents(\n",
        "    semantic_documents,\n",
        "    embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"JohnWickSemantic\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eh_r_-LHmmKn"
      },
      "source": [
        "We'll use naive retrieval for this example."
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 54,
=======
      "execution_count": 45,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
      "metadata": {
        "id": "odVyDUHwZftc"
      },
      "outputs": [],
      "source": [
        "semantic_retriever = semantic_vectorstore.as_retriever(search_kwargs={\"k\" : 10})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mkeiv_ojmp6G"
      },
      "source": [
        "Finally we can create our classic chain!"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 55,
=======
      "execution_count": 46,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
      "metadata": {
        "id": "xWE_0J0mZveG"
      },
      "outputs": [],
      "source": [
        "semantic_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | semantic_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5pfjLQ3ms9_"
      },
      "source": [
        "And view the results!"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 56,
=======
      "execution_count": null,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "0lN2j-e4Z0SD",
        "outputId": "ef483e21-7200-4dfc-b8bf-aed4f23587b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
<<<<<<< HEAD
              "'Based on the reviews in the provided context, people generally liked John Wick. The reviews are mostly positive, praising its action, style, and choreography, with many giving high ratings. However, there are some negative or lower-rated reviews as well, but overall, the sentiment indicates that the film is well-liked by most viewers.'"
            ]
          },
          "execution_count": 56,
=======
              "\"Based on the reviews provided, it seems that people generally liked John Wick. The action sequences, Keanu Reeves' performance, and the unique style of the film were highly praised by reviewers.\""
            ]
          },
          "execution_count": 47,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 57,
=======
      "execution_count": null,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "xdqfBH1SZ3f9",
        "outputId": "ed62b2d1-7586-46cc-aaf4-c54192a56155"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
<<<<<<< HEAD
              "'Yes, there is a review with a rating of 10. The URL to that review is: /review/rw4854296/?ref_=tt_urv'"
            ]
          },
          "execution_count": 57,
=======
              "'Yes, there is one review with a rating of 10 for the movie \"John Wick 3\". Here is the URL to that review: /review/rw4854296/?ref_=tt_urv'"
            ]
          },
          "execution_count": 48,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 58,
=======
      "execution_count": null,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "rAcAObZnZ4o6",
        "outputId": "3f1cade3-41e4-4e42-ef71-048dd18e5e3a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
<<<<<<< HEAD
              "'In the movie John Wick, the story revolves around a retired assassin named John Wick, played by Keanu Reeves, who is seeking revenge after a violent incident. Someone steals his car and kills his beloved dog, which was a gift from his late wife. This act triggers Wick to come out of retirement and hunt down those responsible. Throughout the film, Wick unleashes a relentless and highly stylized campaign of violence against the gangsters involved, all while being a target for numerous bounty hunters and assassins because of a price on his head. The narrative highlights themes of revenge, consequence, and the deadly skills of a former assassin.'"
            ]
          },
          "execution_count": 58,
=======
              "'John Wick is an ultra-violent movie series that follows the story of an ex-hitman seeking revenge after gangsters killed his dog and took everything from him. The first installment features John Wick coming out of retirement to track down those responsible. The series is known for its elaborate action sequences, vivid choreography, and intense violence.'"
            ]
          },
          "execution_count": 49,
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xk2n3-pnVWDJ"
      },
      "source": [
        "# ğŸ¤ Breakout Room Part #2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SkJLYwMVZkj"
      },
      "source": [
        "#### ğŸ—ï¸ Activity #1\n",
        "\n",
        "Your task is to evaluate the various Retriever methods against eachother.\n",
        "\n",
        "You are expected to:\n",
        "\n",
        "1. Create a \"golden dataset\"\n",
        " - Use Synthetic Data Generation (powered by Ragas, or otherwise) to create this dataset\n",
        "2. Evaluate each retriever with *retriever specific* Ragas metrics\n",
        " - Semantic Chunking is not considered a retriever method and will not be required for marks, but you may find it useful to do a \"semantic chunking on\" vs. \"semantic chunking off\" comparision between them\n",
        "3. Compile these in a list and write a small paragraph about which is best for this particular data and why.\n",
        "\n",
        "Your analysis should factor in:\n",
        "  - Cost\n",
        "  - Latency\n",
        "  - Performance\n",
        "\n",
        "> NOTE: This is **NOT** required to be completed in class. Please spend time in your breakout rooms creating a plan before moving on to writing code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWAr16a5XMub"
      },
      "source": [
        "##### HINTS:\n",
        "\n",
        "- LangSmith provides detailed information about latency and cost."
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 73,
      "metadata": {
        "id": "tgDICngKXLGK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PLACEHOLDER: 'documents' variable needs to be defined with your loaded data.\n",
            "PLACEHOLDER: All retriever variables (naive_retriever, bm25_retriever, ensemble_retriever, etc.) need to be defined with actual retriever implementations.\n",
            "WARNING: 'documents' is empty. Using placeholder data for questions and ground truths.\n",
            "\n",
            "Evaluating Naive Retriever...\n",
            "  Processing questions for Naive evaluation...\n",
            "    Processed 5/10 questions for Naive evaluation.\n",
            "    Processed 10/10 questions for Naive evaluation.\n",
            "  Running Ragas.evaluate for Naive...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "273d09efd9b14aae835d824bc9275668",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Completed evaluation of Naive Retriever. Results: {'context_precision': 0.0000, 'context_recall': 0.3000, 'faithfulness': 1.0000, 'answer_relevancy': 0.1850, 'answer_correctness': 0.2150, 'semantic_similarity': 0.8599}\n",
            "\n",
            "Evaluating BM25 Retriever...\n",
            "  Processing questions for BM25 evaluation...\n",
            "    Processed 5/10 questions for BM25 evaluation.\n",
            "    Processed 10/10 questions for BM25 evaluation.\n",
            "  Running Ragas.evaluate for BM25...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "055cb2c9a5ee4ed290d1b272d1521965",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Completed evaluation of BM25 Retriever. Results: {'context_precision': 0.1000, 'context_recall': 0.1000, 'faithfulness': 1.0000, 'answer_relevancy': 0.1000, 'answer_correctness': 0.2160, 'semantic_similarity': 0.8640}\n",
            "\n",
            "Evaluating Contextual Compression Retriever...\n",
            "  Processing questions for Contextual Compression evaluation...\n",
            "    Processed 5/10 questions for Contextual Compression evaluation.\n",
            "    Processed 10/10 questions for Contextual Compression evaluation.\n",
            "  Running Ragas.evaluate for Contextual Compression...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "134e0c2012564c66a198f1573c9f3413",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Completed evaluation of Contextual Compression Retriever. Results: {'context_precision': 0.0000, 'context_recall': 0.3000, 'faithfulness': 1.0000, 'answer_relevancy': 0.0000, 'answer_correctness': 0.2126, 'semantic_similarity': 0.8503}\n",
            "\n",
            "Evaluating Multi-Query Retriever...\n",
            "  Processing questions for Multi-Query evaluation...\n",
            "    Processed 5/10 questions for Multi-Query evaluation.\n",
            "    Processed 10/10 questions for Multi-Query evaluation.\n",
            "  Running Ragas.evaluate for Multi-Query...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "867c26eacefc4899bca3c598038606bd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Completed evaluation of Multi-Query Retriever. Results: {'context_precision': 0.0000, 'context_recall': 0.3000, 'faithfulness': 1.0000, 'answer_relevancy': 0.0000, 'answer_correctness': 0.2159, 'semantic_similarity': 0.8635}\n",
            "\n",
            "Evaluating Parent Document Retriever...\n",
            "  Processing questions for Parent Document evaluation...\n",
            "    Processed 5/10 questions for Parent Document evaluation.\n",
            "    Processed 10/10 questions for Parent Document evaluation.\n",
            "  Running Ragas.evaluate for Parent Document...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6f19715a8c4240ad89669364b01bc467",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Completed evaluation of Parent Document Retriever. Results: {'context_precision': 0.1000, 'context_recall': 0.3000, 'faithfulness': 1.0000, 'answer_relevancy': 0.1000, 'answer_correctness': 0.2159, 'semantic_similarity': 0.8638}\n",
            "\n",
            "Evaluating Ensemble Retriever...\n",
            "  Processing questions for Ensemble evaluation...\n",
            "    Processed 5/10 questions for Ensemble evaluation.\n",
            "    Processed 10/10 questions for Ensemble evaluation.\n",
            "  Running Ragas.evaluate for Ensemble...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "720b9ef9ee214fe785177831400b3f8e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Completed evaluation of Ensemble Retriever. Results: {'context_precision': 0.0000, 'context_recall': 0.2000, 'faithfulness': 1.0000, 'answer_relevancy': 0.2000, 'answer_correctness': 0.2160, 'semantic_similarity': 0.8639}\n",
            "\n",
            "--- Debugging compare_retrievers ---\n",
            "Retriever: Naive, Metrics Scores from Ragas: {}\n",
            "Retriever: BM25, Metrics Scores from Ragas: {}\n",
            "Retriever: Contextual Compression, Metrics Scores from Ragas: {}\n",
            "Retriever: Multi-Query, Metrics Scores from Ragas: {}\n",
            "Retriever: Parent Document, Metrics Scores from Ragas: {}\n",
            "Retriever: Ensemble, Metrics Scores from Ragas: {}\n",
            "--- End Debugging compare_retrievers ---\n",
            "\n",
            "Measuring latency for Naive retriever...\n",
            "  Naive: Avg Latency: 0.0000s, Cost Factor: 1\n",
            "Measuring latency for BM25 retriever...\n",
            "  BM25: Avg Latency: 0.0000s, Cost Factor: 1\n",
            "Measuring latency for Contextual Compression retriever...\n",
            "  Contextual Compression: Avg Latency: 0.0000s, Cost Factor: 3\n",
            "Measuring latency for Multi-Query retriever...\n",
            "  Multi-Query: Avg Latency: 0.0000s, Cost Factor: 3\n",
            "Measuring latency for Parent Document retriever...\n",
            "  Parent Document: Avg Latency: 0.0000s, Cost Factor: 1\n",
            "Measuring latency for Ensemble retriever...\n",
            "  Ensemble: Avg Latency: 0.0000s, Cost Factor: 3\n",
            "\n",
            "--- Final Analysis ---\n",
            "\n",
            "Retriever Performance (Effectiveness):\n",
            "                        Context Precision  Context Recall  Faithfulness  Answer Relevancy  Answer Correctness  Answer Similarity\n",
            "Naive                                 NaN             NaN           NaN               NaN                 NaN                NaN\n",
            "BM25                                  NaN             NaN           NaN               NaN                 NaN                NaN\n",
            "Contextual Compression                NaN             NaN           NaN               NaN                 NaN                NaN\n",
            "Multi-Query                           NaN             NaN           NaN               NaN                 NaN                NaN\n",
            "Parent Document                       NaN             NaN           NaN               NaN                 NaN                NaN\n",
            "Ensemble                              NaN             NaN           NaN               NaN                 NaN                NaN\n",
            "\n",
            "Retriever Efficiency (Latency & Cost):\n",
            "                Retriever  Avg Latency (s)  Cost Factor\n",
            "0                   Naive         0.000006            1\n",
            "1                    BM25         0.000003            1\n",
            "2  Contextual Compression         0.000003            3\n",
            "3             Multi-Query         0.000002            3\n",
            "4         Parent Document         0.000002            1\n",
            "5                Ensemble         0.000002            3\n",
            "\n",
            "--- Recommendation ---\n",
            "\n",
            "To fill in the analysis below, observe the printed tables:\n",
            "\n",
            "Retriever Analysis:\n",
            "\n",
            "Based on our evaluation, the [SEE TABLE - HIGHEST OVERALL SCORES] retriever shows the highest overall performance across metrics like Context Precision, Context Recall, Faithfulness, and Answer Correctness/Similarity.\n",
            "\n",
            "When considering the tradeoffs:\n",
            "\n",
            "1. Effectiveness: The [BEST PERFORMING RETRIEVER FROM TABLE] achieved the highest scores. Note its specific strengths (e.g., high recall, high precision).\n",
            "\n",
            "2. Latency: The [FASTEST RETRIEVER FROM LATENCY TABLE] had the lowest average latency at [ITS LATENCY VALUE] seconds per query, making it ideal for real-time applications if effectiveness is acceptable.\n",
            "\n",
            "3. Cost: The [RETRIEVER WITH LOWEST COST FACTOR AND GOOD SCORES] had the lowest cost factor (likely 1) while maintaining reasonable performance.\n",
            "\n",
            "For this John Wick review dataset:\n",
            "If maximum effectiveness is paramount, I recommend using [BEST PERFORMING RETRIEVER] as it offers the best quality results. It particularly excels at [ITS SPECIFIC STRENGTH e.g., 'providing highly relevant context' or 'generating faithful answers'], which is important for this application.\n",
            "\n",
            "If balancing performance and cost/latency is key, consider [A RETRIEVER THAT IS A GOOD COMPROMISE].\n",
            "\n",
            "If cost is the absolute primary concern, [MOST COST-EFFECTIVE RETRIEVER WITH ACCEPTABLE SCORES] provides a good alternative.\n",
            "\n",
            "If speed is critical, [FASTEST RETRIEVER] is the choice, provided its effectiveness meets the minimum requirements.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "from ragas import evaluate\n",
        "from ragas.metrics import (\n",
        "    context_precision, context_recall, faithfulness, answer_relevancy, \n",
        "    answer_correctness, answer_similarity\n",
        ")\n",
        "from datasets import Dataset\n",
        "from langchain_core.runnables import RunnablePassthrough, RunnableLambda # Added RunnableLambda\n",
        "from operator import itemgetter\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.documents import Document # Added Document import\n",
        "\n",
        "# Placeholder for where 'documents' would be loaded (e.g., from CSVs)\n",
        "# This list needs to be populated with your actual document objects or texts.\n",
        "# For example:\n",
        "# documents = [Document(page_content=\"Review 1...\"), Document(page_content=\"Review 2...\")]\n",
        "print(\"PLACEHOLDER: 'documents' variable needs to be defined with your loaded data.\")\n",
        "documents = [] \n",
        "\n",
        "questions = [\n",
        "    \"Did people generally like John Wick?\",\n",
        "    \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\",\n",
        "    \"What happened in John Wick?\",\n",
        "    \"What were the main criticisms of John Wick 2?\",\n",
        "    \"What do reviewers say about Keanu Reeves' performance?\",\n",
        "    \"How does John Wick 4 compare to the previous films?\",\n",
        "    \"What are the most violent scenes described in reviews?\",\n",
        "    \"What common themes appear across all John Wick movie reviews?\",\n",
        "    \"Which John Wick movie had the highest-rated reviews?\",\n",
        "    \"What plot elements do viewers find unrealistic in John Wick movies?\"\n",
        "]\n",
        "\n",
        "llm = ChatOpenAI(model_name=\"gpt-4.1-nano\")\n",
        "\n",
        "# CORRECTED PlaceholderRetriever to return Document objects\n",
        "class PlaceholderRetriever:\n",
        "    def __init__(self, name=\"placeholder\"):\n",
        "        self.name = name\n",
        "    def invoke(self, query: str):\n",
        "        # print(f\"PlaceholderRetriever ({self.name}) invoked for: {query}\") # Can be verbose\n",
        "        # Return a list of Document objects\n",
        "        return [Document(page_content=f\"Placeholder context from {self.name} for query: {query}\")]\n",
        "\n",
        "print(\"PLACEHOLDER: All retriever variables (naive_retriever, bm25_retriever, ensemble_retriever, etc.) need to be defined with actual retriever implementations.\")\n",
        "naive_retriever = PlaceholderRetriever(\"naive\")\n",
        "bm25_retriever = PlaceholderRetriever(\"bm25\")\n",
        "compression_retriever = PlaceholderRetriever(\"compression\")\n",
        "multi_query_retriever = PlaceholderRetriever(\"multi_query\")\n",
        "parent_document_retriever = PlaceholderRetriever(\"parent_document\")\n",
        "ensemble_retriever = PlaceholderRetriever(\"ensemble\") # Also used in generate_golden_dataset\n",
        "\n",
        "def generate_golden_dataset(questions_list, docs_for_context, llm_model, retriever_for_gt_context):\n",
        "    print(f\"Generating golden dataset using {type(retriever_for_gt_context).__name__} for context...\")\n",
        "    all_contexts = []\n",
        "    ground_truth_answers = []\n",
        "    \n",
        "    for i, question in enumerate(questions_list):\n",
        "        print(f\"  Generating GT for question {i+1}/{len(questions_list)}: \\\"{question[:50]}...\\\"\")\n",
        "        context_docs = retriever_for_gt_context.invoke(question)\n",
        "        context_texts = [doc.page_content for doc in context_docs if hasattr(doc, 'page_content')]\n",
        "        full_context = \"\\n\\n\".join(context_texts)\n",
        "        all_contexts.append(full_context)\n",
        "        \n",
        "        prompt_text = f\"\"\"\n",
        "        Based on the following context about John Wick movie reviews, please answer this question comprehensively:\n",
        "        \n",
        "        Question: {question}\n",
        "        \n",
        "        Context:\n",
        "        {full_context}\n",
        "        \n",
        "        Answer:\n",
        "        \"\"\"\n",
        "        \n",
        "        try:\n",
        "            ground_truth = llm_model.invoke(prompt_text).content\n",
        "            ground_truth_answers.append(ground_truth)\n",
        "        except Exception as e:\n",
        "            print(f\"    Error generating ground truth for question '{question}': {e}\")\n",
        "            ground_truth_answers.append(f\"Error generating answer: {e}\")\n",
        "    \n",
        "    return questions_list, all_contexts, ground_truth_answers\n",
        "\n",
        "if documents: # Only run if documents are loaded\n",
        "     questions_list, golden_contexts_list, ground_truth_answers_list = generate_golden_dataset(questions, documents, llm, ensemble_retriever)\n",
        "else:\n",
        "     print(\"WARNING: 'documents' is empty. Using placeholder data for questions and ground truths.\")\n",
        "     questions_list = questions # Use the global questions list\n",
        "     ground_truth_answers_list = [\"Placeholder GT for \" + q for q in questions_list]\n",
        "\n",
        "\n",
        "data_for_evaluation_loop = {\n",
        "    \"question\": questions_list,\n",
        "    \"ground_truth\": ground_truth_answers_list\n",
        "}\n",
        "test_dataset_hf = Dataset.from_dict(data_for_evaluation_loop)\n",
        "\n",
        "ragas_metrics_list = [\n",
        "    context_precision,\n",
        "    context_recall,\n",
        "    faithfulness,\n",
        "    answer_relevancy,\n",
        "    answer_correctness,\n",
        "    answer_similarity\n",
        "]\n",
        "\n",
        "def evaluate_retriever(retriever_to_eval, retriever_name, hf_dataset, llm_model, metrics_list):\n",
        "    # print(f\"  Configuring RAG chain for {retriever_name} evaluation...\") # Can be verbose\n",
        "    prompt_template_for_eval = ChatPromptTemplate.from_template(\n",
        "        \"\"\"Answer the question based *only* on the following context:\n",
        "        Context:\n",
        "        {context}\n",
        "\n",
        "        Question: {question}\n",
        "        \n",
        "        Answer:\"\"\"\n",
        "    )\n",
        "\n",
        "    context_preparation_chain = (\n",
        "        itemgetter(\"question\")\n",
        "        | RunnableLambda(retriever_to_eval.invoke)\n",
        "        | RunnableLambda(lambda docs: [doc.page_content for doc in docs if hasattr(doc, 'page_content')])\n",
        "    )\n",
        "\n",
        "    rag_chain_for_eval = (\n",
        "        {\n",
        "            \"context\": context_preparation_chain,\n",
        "            \"question\": itemgetter(\"question\")\n",
        "        }\n",
        "        | prompt_template_for_eval\n",
        "        | llm_model\n",
        "        | RunnableLambda(lambda x: x.content if hasattr(x, 'content') else str(x))\n",
        "    )\n",
        "\n",
        "    generated_answers = []\n",
        "    retrieved_contexts_for_ragas = []\n",
        "    questions_for_ragas = []\n",
        "    ground_truths_for_ragas_in_eval = []\n",
        "\n",
        "    print(f\"  Processing questions for {retriever_name} evaluation...\")\n",
        "    for i, item in enumerate(hf_dataset):\n",
        "        current_question = item[\"question\"]\n",
        "        current_ground_truth = item[\"ground_truth\"]\n",
        "        \n",
        "        # print(f\"    Generating answer for Q{i+1} ({retriever_name}): \\\"{current_question[:50]}...\\\"\") # Can be verbose\n",
        "        try:\n",
        "            generated_answer = rag_chain_for_eval.invoke({\"question\": current_question})\n",
        "        except Exception as e:\n",
        "            print(f\"      Error generating answer via RAG chain for question '{current_question}' with {retriever_name}: {e}\")\n",
        "            generated_answer = f\"Error in RAG chain: {e}\"\n",
        "\n",
        "        # print(f\"    Retrieving context for Q{i+1} ({retriever_name})...\") # Can be verbose\n",
        "        try:\n",
        "            docs = retriever_to_eval.invoke(current_question)\n",
        "            current_contexts_list = [doc.page_content for doc in docs if hasattr(doc, 'page_content')]\n",
        "        except Exception as e:\n",
        "            print(f\"      Error retrieving context for question '{current_question}' with {retriever_name}: {e}\")\n",
        "            current_contexts_list = [f\"Error retrieving context: {e}\"]\n",
        "\n",
        "        generated_answers.append(generated_answer)\n",
        "        retrieved_contexts_for_ragas.append(current_contexts_list)\n",
        "        questions_for_ragas.append(current_question)\n",
        "        ground_truths_for_ragas_in_eval.append(current_ground_truth)\n",
        "        \n",
        "        if (i + 1) % 5 == 0 or (i + 1) == len(hf_dataset): # Print progress less frequently\n",
        "             print(f\"    Processed {i+1}/{len(hf_dataset)} questions for {retriever_name} evaluation.\")\n",
        "\n",
        "    data_for_ragas_eval = {\n",
        "        \"question\": questions_for_ragas,\n",
        "        \"answer\": generated_answers,\n",
        "        \"contexts\": retrieved_contexts_for_ragas,\n",
        "        \"ground_truth\": ground_truths_for_ragas_in_eval \n",
        "    }\n",
        "    ragas_eval_dataset = Dataset.from_dict(data_for_ragas_eval)\n",
        "\n",
        "    print(f\"  Running Ragas.evaluate for {retriever_name}...\")\n",
        "    try:\n",
        "        evaluation_output = evaluate(\n",
        "            dataset=ragas_eval_dataset,\n",
        "            metrics=metrics_list,\n",
        "            llm=llm_model,\n",
        "            raise_exceptions=False \n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"    Error during Ragas evaluate for {retriever_name}: {e}\")\n",
        "        evaluation_output = {metric.__name__: float('nan') for metric in metrics_list}\n",
        "\n",
        "    return {\"retriever\": retriever_name, \"results\": evaluation_output}\n",
        "\n",
        "retrievers = {\n",
        "    \"Naive\": naive_retriever,\n",
        "    \"BM25\": bm25_retriever,\n",
        "    \"Contextual Compression\": compression_retriever,\n",
        "    \"Multi-Query\": multi_query_retriever,\n",
        "    \"Parent Document\": parent_document_retriever,\n",
        "    \"Ensemble\": ensemble_retriever,\n",
        "}\n",
        "\n",
        "evaluation_results = []\n",
        "\n",
        "for name, retriever_instance in retrievers.items():\n",
        "    print(f\"\\nEvaluating {name} Retriever...\")\n",
        "    result = evaluate_retriever(retriever_instance, name, test_dataset_hf, llm, ragas_metrics_list)\n",
        "    evaluation_results.append(result)\n",
        "    print(f\"Completed evaluation of {name} Retriever. Results: {result['results']}\")\n",
        "\n",
        "def compare_retrievers(eval_results_list):\n",
        "    comparison_data = {}\n",
        "    print(\"\\n--- Debugging compare_retrievers ---\") # Added debug print\n",
        "    for res in eval_results_list:\n",
        "        retriever_name = res[\"retriever\"]\n",
        "        metrics_scores = res[\"results\"] if isinstance(res[\"results\"], dict) else {}\n",
        "        \n",
        "        # Debug print to see what's in metrics_scores for each retriever\n",
        "        print(f\"Retriever: {retriever_name}, Metrics Scores from Ragas: {metrics_scores}\") \n",
        "        \n",
        "        comparison_data[retriever_name] = {\n",
        "            \"Context Precision\": metrics_scores.get(\"context_precision\", float('nan')),\n",
        "            \"Context Recall\": metrics_scores.get(\"context_recall\", float('nan')),\n",
        "            \"Faithfulness\": metrics_scores.get(\"faithfulness\", float('nan')),\n",
        "            \"Answer Relevancy\": metrics_scores.get(\"answer_relevancy\", float('nan')),\n",
        "            \"Answer Correctness\": metrics_scores.get(\"answer_correctness\", float('nan')),\n",
        "            \"Answer Similarity\": metrics_scores.get(\"semantic_similarity\", float('nan')) # Key is \"semantic_similarity\"\n",
        "        }\n",
        "    print(\"--- End Debugging compare_retrievers ---\\n\") # Added debug print\n",
        "    comparison_df = pd.DataFrame.from_dict(comparison_data, orient='index')\n",
        "    return comparison_df\n",
        "\n",
        "comparison_results_df = compare_retrievers(evaluation_results)\n",
        "\n",
        "def plot_comparison(df_to_plot): # Function definition remains, but won't be called\n",
        "    if df_to_plot.empty:\n",
        "        print(\"Comparison DataFrame is empty. Skipping plot.\")\n",
        "        return\n",
        "    ax = df_to_plot.plot(linestyle='None', marker='o', figsize=(14, 9), markersize=8) \n",
        "    plt.title('Retriever Performance Comparison (Metrics as Dots)')\n",
        "    plt.ylabel('Score (0.0 - 1.0)')\n",
        "    plt.xlabel('Retrievers')\n",
        "    plt.xticks(rotation=45, ha=\"right\")\n",
        "    ax.legend(title='Metrics', bbox_to_anchor=(1.05, 1), loc='upper left') \n",
        "    plt.grid(axis='y', linestyle='--')\n",
        "    plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
        "    plt.savefig('retriever_comparison_dots.png')\n",
        "    print(\"Retriever comparison dot plot saved as retriever_comparison_dots.png\")\n",
        "    plt.show()\n",
        "\n",
        "def measure_latency_and_cost(retrievers_dict, questions_to_test):\n",
        "    latency_results = []\n",
        "    for name, retriever_instance in retrievers_dict.items():\n",
        "        print(f\"Measuring latency for {name} retriever...\")\n",
        "        total_time = 0\n",
        "        num_questions = len(questions_to_test)\n",
        "        if num_questions == 0:\n",
        "            print(f\"  Skipping latency for {name} as there are no test questions.\")\n",
        "            avg_latency = float('nan')\n",
        "        else:\n",
        "            for i, question in enumerate(questions_to_test):\n",
        "                # print(f\"    Latency test Q{i+1}/{num_questions} for {name}...\") # Can be verbose\n",
        "                start_event = time.time()\n",
        "                try:\n",
        "                    _ = retriever_instance.invoke(question)\n",
        "                except Exception as e:\n",
        "                    print(f\"      Error during latency test for {name} on question '{question}': {e}\")\n",
        "                end_event = time.time()\n",
        "                total_time += (end_event - start_event)\n",
        "            avg_latency = total_time / num_questions if num_questions > 0 else float('nan')\n",
        "        \n",
        "        cost_factor = 1 \n",
        "        if any(keyword in str(type(retriever_instance)).lower() for keyword in [\"openai\", \"gpt\"]) or \\\n",
        "           any(keyword in name.lower() for keyword in [\"compression\", \"multi-query\", \"ensemble\"]):\n",
        "            cost_factor = 3 \n",
        "        elif hasattr(retriever_instance, 'llm') and retriever_instance.llm and \\\n",
        "             any(keyword in str(type(retriever_instance.llm)).lower() for keyword in [\"openai\", \"gpt\"]):\n",
        "            cost_factor = 3\n",
        "        elif hasattr(retriever_instance, 'retriever') and hasattr(retriever_instance.retriever, 'llm') and \\\n",
        "             retriever_instance.retriever.llm and \\\n",
        "             any(keyword in str(type(retriever_instance.retriever.llm)).lower() for keyword in [\"openai\", \"gpt\"]):\n",
        "            cost_factor = 3\n",
        "\n",
        "        latency_results.append({\n",
        "            \"Retriever\": name,\n",
        "            \"Avg Latency (s)\": avg_latency,\n",
        "            \"Cost Factor\": cost_factor\n",
        "        })\n",
        "        print(f\"  {name}: Avg Latency: {avg_latency:.4f}s, Cost Factor: {cost_factor}\")\n",
        "    return pd.DataFrame(latency_results)\n",
        "\n",
        "latency_cost_df = measure_latency_and_cost(retrievers, questions_list)\n",
        "\n",
        "print(\"\\n--- Final Analysis ---\")\n",
        "print(\"\\nRetriever Performance (Effectiveness):\")\n",
        "print(comparison_results_df.to_string())\n",
        "\n",
        "print(\"\\nRetriever Efficiency (Latency & Cost):\")\n",
        "print(latency_cost_df.to_string())\n",
        "\n",
        "# plot_comparison(comparison_results_df) # This line is now commented out\n",
        "\n",
        "print(\"\"\"\n",
        "--- Recommendation ---\n",
        "\n",
        "To fill in the analysis below, observe the printed tables:\n",
        "\n",
        "Retriever Analysis:\n",
        "\n",
        "Based on our evaluation, the [SEE TABLE - HIGHEST OVERALL SCORES] retriever shows the highest overall performance across metrics like Context Precision, Context Recall, Faithfulness, and Answer Correctness/Similarity.\n",
        "\n",
        "When considering the tradeoffs:\n",
        "\n",
        "1. Effectiveness: The [BEST PERFORMING RETRIEVER FROM TABLE] achieved the highest scores. Note its specific strengths (e.g., high recall, high precision).\n",
        "\n",
        "2. Latency: The [FASTEST RETRIEVER FROM LATENCY TABLE] had the lowest average latency at [ITS LATENCY VALUE] seconds per query, making it ideal for real-time applications if effectiveness is acceptable.\n",
        "\n",
        "3. Cost: The [RETRIEVER WITH LOWEST COST FACTOR AND GOOD SCORES] had the lowest cost factor (likely 1) while maintaining reasonable performance.\n",
        "\n",
        "For this John Wick review dataset:\n",
        "If maximum effectiveness is paramount, I recommend using [BEST PERFORMING RETRIEVER] as it offers the best quality results. It particularly excels at [ITS SPECIFIC STRENGTH e.g., 'providing highly relevant context' or 'generating faithful answers'], which is important for this application.\n",
        "\n",
        "If balancing performance and cost/latency is key, consider [A RETRIEVER THAT IS A GOOD COMPROMISE].\n",
        "\n",
        "If cost is the absolute primary concern, [MOST COST-EFFECTIVE RETRIEVER WITH ACCEPTABLE SCORES] provides a good alternative.\n",
        "\n",
        "If speed is critical, [FASTEST RETRIEVER] is the choice, provided its effectiveness meets the minimum requirements.\n",
        "\"\"\")\n"
=======
      "execution_count": null,
      "metadata": {
        "id": "tgDICngKXLGK"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE"
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
<<<<<<< HEAD
      "version": "3.13.2"
=======
      "version": "3.13.3"
>>>>>>> 773786fa013f1300968e0183946b5726f298e4ee
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
